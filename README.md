# Awsome-Visual-MLPs
Collect some MLPs with Computer-Vision (CV) papers.  If you find some ignored papers, please open issues or pull requests.


## Papers

### Transformer original paper

- [Attention is All You Need](https://arxiv.org/abs/1706.03762) (NIPS 2017)

### Technical blog

- [Chinese Blog] 3W字长文带你轻松入门视觉transformer [[Link](https://zhuanlan.zhihu.com/p/308301901)]
- [Chinese Blog] Vision Transformer 超详细解读 (原理分析+代码解读) [[Link](https://zhuanlan.zhihu.com/p/348593638)]

### Survey
  - Transformers in Vision: A Survey [[paper](https://arxiv.org/abs/2101.01169)]   - 2021.02.22
  - A Survey on Visual Transformer [[paper](https://arxiv.org/abs/2012.12556)]   - 2020.1.30

### arXiv papers
- **[SegFormer]** SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers [paper](https://arxiv.org/abs/2105.15203) [[code](https://github.com/NVlabs/SegFormer)]
- **[SDNet]** SDNet: mutil-branch for single image deraining using swin [[paper](https://arxiv.org/abs/2105.15077)] [[code](https://github.com/H-tfx/SDNet)]
- **[DVT]** Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length [[paper](https://arxiv.org/abs/2105.15075)]
- Dual-stream Network for Visual Recognition [[paper](https://arxiv.org/abs/2105.14734)]
- Gaze Estimation using Transformer [[paper](https://arxiv.org/abs/2105.14424)] [[code](https://github.com/yihuacheng/GazeTR)]
- Transformer-Based Deep Image Matching for Generalizable Person Re-identification [[paper](https://arxiv.org/abs/2105.14432)]
- Less is More: Pay Less Attention in Vision Transformers [[paper](https://arxiv.org/abs/2105.14217)] 
- FoveaTer: Foveated Transformer for Image Classification [[paper](https://arxiv.org/abs/2105.14173)]
- Transformer-Based Source-Free Domain Adaptation [[paper](https://arxiv.org/abs/2105.14138)] [[code](https://github.com/ygjwd12345/TransDA)]
- An Attention Free Transformer [[paper](https://arxiv.org/abs/2105.14103)]
- **[PTNet]** PTNet: A High-Resolution Infant MRI Synthesizer Based on Transformer [[paper](https://arxiv.org/abs/2105.13993)]
- ResT: An Efficient Transformer for Visual Recognition [[paper](https://arxiv.org/abs/2105.13677)] [[code](https://github.com/wofmanaf/ResT)]
- CogView: Mastering Text-to-Image Generation via Transformers [[paper](https://arxiv.org/abs/2105.13290)]
- KVT: k-NN Attention for Boosting Vision Transformers [[paper](https://www.researchgate.net/publication/351905425_KVT_k-NN_Attention_for_Boosting_Vision_Transformers)]
- **[NesT]** Aggregating Nested Transformers [[paper](https://arxiv.org/abs/2105.12723)] 
- **[TAPG]** Temporal Action Proposal Generation with Transformers [[paper](https://arxiv.org/abs/2105.12043)] 
- Boosting Crowd Counting with Transformers [[paper](https://arxiv.org/abs/2105.10926)] 
- COTR: Convolution in Transformer Network for End to End Polyp Detection [[paper](https://arxiv.org/abs/2105.10925)]
- **[TransVOD]** End-to-End Video Object Detection with Spatial-Temporal Transformers [[paper](https://arxiv.org/abs/2105.10920)] [[code](https://github.com/SJTU-LuHe/TransVOD)]
- Intriguing Properties of Vision Transformers [[paper](https://arxiv.org/abs/2105.10497)] [[code](https://git.io/Js15X)] 
- Combining Transformer Generators with Convolutional Discriminators [[paper](https://arxiv.org/abs/2105.10189)]
- Rethinking the Design Principles of Robust Vision Transformer [[paper](https://arxiv.org/abs/2105.07926)]
- Vision Transformers are Robust Learners [[paper](https://arxiv.org/abs/2105.07581)] [[code](https://git.io/J3VO0)]
- Manipulation Detection in Satellite Images Using Vision Transformer [[paper](https://arxiv.org/abs/2105.06373)]
- **[Segmenter]** Segmenter: Transformer for Semantic Segmentation [[paper](https://arxiv.org/abs/2105.05633)] [[code](https://github.com/rstrudel/segmenter)]
- **[Swin-Unet]** Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation [[paper](https://arxiv.org/abs/2105.05537)] [[code](https://github.com/HuCaoFighting/Swin-Unet)]
- Self-Supervised Learning with Swin Transformers [[paper](https://arxiv.org/abs/2105.04553)] [[code](https://github.com/SwinTransformer/Transformer-SSL)]
- **[SCTN]** SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation [[paper](https://arxiv.org/abs/2105.04447)] 
